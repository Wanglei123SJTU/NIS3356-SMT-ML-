# Temporal heat analysis and prediction of social platform topics


## 背景与需求分析

### 介绍
社交平台作为信息传播的重要场所，用户在平台上产生海量内容，其中包括文本、图片、视频等。为深入了解社交平台上话题的演化和热度变化，我们计划引入人工智能方法进行话题提取，并融合时序分析，以全面分析和可视化话题在时间轴上的热度趋势。
我们组希望构建一个系统，通过Bertopic算法实现社交平台上话题的自动提取，并结合时序分析方法，实现对话题热度在不同时间点的变化进行监测、分析和可视化。

### 需求背景

经过前期调研，我们发现目前社交媒体存在如下需求：

1.发现热门话题：准确地捕捉到热门话题的浮动和变化。

2.分析话题趋势：通过追踪话题热度随时间的变化，可以了解话题的兴衰、持续时间、高峰期等特征。

3.掌握舆情动向：了解当前社会舆论的倾向和情绪，帮助政府、企业、组织等进行舆情监测和管理。

4.研究社会心理：可以揭示人们的兴趣爱好、关注焦点、情感变化等社会心理特征。这对于社会学、心理学等领域的研究非常有价值。

5.市场洞察分析：通过了解公众对不同话题的关注程度和趋势，企业可以洞察市场需求和消费者心理，调整产品策略、开展精准营销，提高市场竞争力。

### 挑战
经过分析，系统实现主要面临以下四方面的挑战

* 批量获取社交网络的数据集以供分析
* 对数据集内容进行可信的分类
* 对分类结果进行有效的分析
* 对分析内容进行合理的比较并得出结论


## 数据获取与预处理
使用爬虫对微博、知乎的数据进行爬取和处理，获得json格式带有时间、话题、热度的数据。
### 数据获取与爬虫
#### 今日头条
考虑到测试分类效果的需要，在对具体内容分类之前，需要一组已经完成标注的数据集。通过网络搜索，发现一组今日头条的数据满足要求，共计382688条数据，其中格式如下：

数据格式：ID\_!\_TYPE\_!\_TAG\_!\_TITLE

ID:用于唯一标识新闻的ID 

TYPE：新闻分类

TAG：新闻的分区

TITLE：新闻标题

而采用今日头条之类新闻数据集的优点为：自身附带分类、文本质量较高，标题与新闻内容相关性较好
#### 微博

在网络上获得了微博平台从2022.1.1到2022.12.31的全部热榜信息与热度，共获得137665条数据，格式如下：  

\_id：指向新闻的唯一id

date：新闻发布的时间

duration：在热榜上持续的时间

fenlei：新闻所属分类

hotNumber：新闻热度

screenId/screenName：消息来源对应的ID/名称

topic：新闻所属话题
#### 知乎
使用网络数据与爬虫相结合的方式，从知乎平台获得了从2022.1.1到12.31（每两小时更新一次）的问题热榜与热度，共获得18194条数据

time：知乎热榜的时间戳

title：知乎热榜的问题标题

hot：知乎热榜的热度

### 数据预处理

#### 中文分词
我们在表示信息的时候，会使用一些高频出现、但是和“noise”一样不重要的词语。学者们为这种高频、低价值的词语起了个名字，即前面提到的”停用词”。在设计系统时，我们导入开源库cntext中的STOPWORDS.pkl作为停用词库，并使用中文语言处理中使用最广泛的jieba进行分词。

#### 词嵌入
词嵌入是自然语言处理中将单词与汉字转换为向量的关键操作，单个词在预定义的向量空间中被表示为实数向量，每个单词都映射到一个向量。通过词嵌入这种方式将单词转变为词向量，机器便可对单词进行计算，通过计算不同词向量之间夹角余弦值cosine而得出单词之间的相似性。

Word2Vec是一种用于有效学习从文本语料库嵌入的独立词语的统计方法。其核心思想就是基于上下文，先用向量代表各个词，然后通过一个预测目标函数学习这些向量的参数。Word2Vec的网络主体是一种单隐层前馈神经网络，网络的输入和输出均为词向量。


本系统使用Word2Vec模型进行词嵌入，并使用KeyedVectors库加载中文词向量信息。考虑到新闻与论坛的信息特异性，从网络上搜集多种类型词向量模型进行测试.


## 算法应用与实现

### 聚类算法选择

#### K-means
K-means算法的原理如下：预将数据分为K组，随机选取K个对象作为初始的聚类中心，然后计算每个对象与各个种子聚类中心之间的距离，把每个对象分配给距离它最近的聚类中心。这个过程将不断重复重新计算直到满足某个终止条件。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{Km.png}
    \caption{词向量模型信息}
\end{figure} 

#### HDBSCAN
HDBSCAN算法的原理如下：基于密度的聚类算法通过寻找被低密度区域分离的高密度区域，并将高密度区域作为一个聚类的“簇”。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{HB.png}
    \caption{词向量模型信息}
    \end{figure} 

#### OPTICS
OPTICS算法的原理如下：OPTICS并不显式的生成数据聚类结果，只是对数据集中的对象进行排序，得到一个有序的对象列表，通过该有序列表，可以得到一个决策图，通过决策图可以选择不同的eps参数进行DBSCAN聚类。

### 算法比较
通过今日头条已经分类的数据集，进行不同聚类算法准确率的多轮测试，其中以“娱乐，科技，体育，军事”四分组任务作为基准

### 分类参数选择
使用效果最好的HDBSCAN聚类算法，考虑到计算效率，使用UMAP算法进行特征降维

UMAP是一种降维技术，假设可用数据样本均匀（Uniform）分布在拓扑空间（Manifold）中，可以从这些有限数据样本中近似（Approximation）并映射（Projection）到低维空间。

在试验中主要调整的UMAP参数如下：

n\_neighbors:降维过程中保留的局部邻域信息的数量。
较小的值将通过限制在分析高维数据时考虑的相邻点的数量来推动UMAP更多地关注局部结构，
而较大的值将推动UMAP代表全局结构，可能会丢失一些局部信息。

n\_components:降维过程中保留的维度。
维度过小可能丢失信息。

在试验中主要调整的HDBSCAN参数如下：

min\_cluster\_size:一个簇中最小的数据点数量
数量越大意味着判断称为类的条件越苛刻，类别越少。

'euclidean':此处用欧式距离衡量
'emo':基于聚类簇在数据集中的密度分布

经过测试，UMAP的降维数微调对效果提高影响不大，不过聚类的最小簇在聚类时起关键作用。对于今日头条一类已经经过明确分类都数据，使用略小于每类数据总量的最小簇数量可以有效的保证分类效果较好。

对于微博，知乎这类分类不明显的数据，设置最小簇数量时也要考虑时间片的大小和数据量的大小。如果设置最小簇过小，就会出现大量杂乱的分类，影响分析的精度；如果设置最小簇过大，就会出现许多距离相对较远的数据被聚到同一类的情况，同样会干扰到最后的分析。

### 模块化处理
综上所述，实际应用的聚类模型呈模块化

\subsection{时序主题热度分析}
对时序主题的热度分析共分为以下步骤：

1. 基于时间片划分数据集，考虑到时序逻辑，将数据集按照预设的3天为界限进行划分，对其中的每一时间片进行后续处理

2. 筛选剔除过小的数据，考虑到微博热榜中存在大量单个姓名和单个事件名称的数据，这些数据信息量较小的混杂干扰分析结果，因此在聚类分析之前筛选掉这些词内容过少的数据。

3. 将数据按时间片顺序分别进行聚类，并储存聚类结果。

4. 对聚类得到的结果压缩至标定的四个类别，如果关键词相似度>50\%则允许归类
对于类别较少的数据允许放入一类，类别较多的数据可能会存在分入多个数据集的问题，允许放入两类。

时序分析的具体代码在PPT中已经放置，同时已经上传到开源库Github，链接为https://github.com/faiimea/NIS3356-SMT


## 实验与结果分析
### 微博时序热度分析

进行聚类，得到热度折线图如下图所示，一个尖峰代表当个时间片存在较为热门的该主题事件。

经过单独分析，可以得出结论：主题与主题之间存在差别性与较强的相关性，从一年的时间维度看，微博的用户比较关心【综艺、电视剧、电影】的问题，政治在四个话题中讨论最少，这与微博平台的泛娱乐化以及较为严格舆论管制有联系。


经过单独分析，可以得出结论：主题与主题之间存在差别与相关性。从一年的时间维度看，知乎的用户比较关心【生活、健康、情感、家庭】的问题，但四个话题之间总体差别不大。

### 不同论坛热度比较
通过对不同论坛热度时序图的比较，可以看出不同论坛在同一时间对某些热点事件的讨论程度差异，而这样的差异也是与论坛用户，管理风格，事件类型有关。
W